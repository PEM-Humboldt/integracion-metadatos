---
title: "Estructura y descripción de los metadatos de Ceiba"
author: "Marius Bottin"
date: "`r Sys.Date()`"
output: 
    bookdown::github_document2:
       number_sections: true
       toc: true
---


```{r setup}
require(RPostgreSQL)
require(dm)
require(png)
knitr::opts_chunk$set(cache=T,tidy.opts = list(width.cutoff = 70),
                     tidy = TRUE,
                     max.print=50,fig.path="./Fig/explor_ceiba_",echo=T,
                     collapse=F, echo=T)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  paste0("\n \\", "footnotesize","\n\n", x, "\n\n \\normalsize\n\n")
})
```
# Datadir en el servidor Ceiba

## Descripción
Todos los datos de Ceiba están organizados como carpetas en el datadir del servidor.
Se maneja después con el sistema Integrated Publishing Toolkit desarrollado por GBIF.

En cada carpeta (cada juego de datos), podemos encontrar:

* el archivo comprimido que contiene los archivos y los metadatos en formato DarwinCore completo.
* el archivo `eml.xml` que contiene los metadatos, y todas las versiones del archivo (con los nombres `eml-1.xml`, `eml-2.xml` etc)
* el archivo `publication.log` que contiene el historial de publicación/modificación del juego de datos
* archivos de descripción de los juegos de datos en "Rich Text Format" (rtf), tambien para cada versión publicada
* archivos de administración de datos y metadatos `resource.xml`
* una carpeta `sources` que contiene los datos (?)

## Extracción de los metadatos

En ssh, accedemos al servidor de ceiba desde la red del instituto:

```bash
ssh integracion@192.168.11.74
```

Extraemos 3 archivos:

* un archivo que tiene las direcciones de los archivos "eml.xml" y sus contenidos
* un archivo que contiene las direcciones de los archivos "resource.xml" y sus contenidos
* un catalogo de todos los archivos presentes en la carpeta de datos manejada por el ipt

Esos 2 archivos se pueden obtener con:

```bash
find /home/pem/datadir/ -name eml.xml -exec bash file_and_content.sh {} \; >file_and_content_result_eml 2> errors_find_file_and_content_eml
find /home/pem/datadir/ -name resource.xml  -exec bash file_and_content.sh {} \; >file_and_content_result_resource 2> errors_find_file_and_content_resource
find /home/pem/datadir/ -type f  > result_find
```

Los archivos se pueden descargar desde la red del instituto, gracias al applicativo scp, que funciona a través de ssh.

# Analisis de los metadatos

```{r}
result_find <- readLines("../../../data_metadatos_catalogos/ceiba/result_find")
meta_ceiba <- readLines("../../../data_metadatos_catalogos/ceiba/file_and_content_result_eml")
meta_ceiba<-meta_ceiba[!meta_ceiba==""]
```

Numero de archivos de metadatos

```{r}
sum(grepl("---file:.*---",meta_ceiba))
```

We search for the names/pathes of the files and we create the tables describing the adresses in the R object

```{r}
nameFilesAddr<-grep("---file:.*---",meta_ceiba)
addresses_xml<-data.frame(
  file=sub("^---file:(.*)---$","\\1",meta_ceiba[nameFilesAddr]),
  beg=nameFilesAddr+1,
  end=c(nameFilesAddr[2:length(nameFilesAddr)]-1,length(meta_ceiba))
)
```

Checking integrity and correspondances with the other objects

```{r}
any(duplicated(addresses_xml$file))
match(addresses_xml$file,result_find)
```
There might be a problem when there is an empty xml.
After manual checking, we realize that this problem creates an end before the beg, so to avoid these lines in the rest of the code, we just suppress these cases in the addresses_xml object:

```{r}
w_empty<-which((addresses_xml$beg[1:(nrow(addresses_xml)-1)]+1)==addresses_xml$beg[2:nrow(addresses_xml)])
addresses_xml[(w_empty-2):(w_empty+2),]

addresses_xml[addresses_xml$beg>addresses_xml$end,]
addresses_xml<-addresses_xml[addresses_xml$beg<addresses_xml$end,]
```


Separating by origin files:

```{r}
xml_files<-apply(addresses_xml,1,function(a,rl)paste(rl[a[2]:a[3]],sep="\n",collapse="\n"),rl=meta_ceiba)
names(xml_files)<-addresses_xml$file
```

Then reading the xml code:

```{r}
require(XML)
require(xml2)
xml_list<-lapply(xml_files,function(x)xmlToList(xmlParse(x)))
```

I gotta check this part because it does not make sense: this only take the large categories which are:

* dataset
* additionalMetadata
* .attrs

```r
names1<-names(xml_list[[1]])
names_all<-lapply(xml_list,names) 
sapply(names_all,function(x,y)!all(y==x),y=names1)
(names_fields<-unique(Reduce(c,names_all)))
mostComplete<-which.max(sapply(names_all,function(x,y)sum(y%in%x),y=names_fields))
  
```

Seems that part is useless as well:

```r
level1<-data.frame(
  name=names_fields,
  hasValue=F
)
A<-sapply(xml_list,names)
A_corres<-data.frame(
  lev0_nb=rep(1:length(A),sapply(A,length)),
  lev1_nb=unlist(lapply(A,function(x)1:length(x))),
  level1_match=unlist(lapply(A,function(x,y)match(x,y),y=level1$name))
)
LIST<- ISNULL <- logical(length=nrow(A_corres))
LENGTH <- DEPTH <- numeric(length=nrow(A_corres))
# NAMES <- list()
# for(i in 1:nrow(A_corres))LIST[i]<-is.list(xml_list[[A_corres[i,1]]][[A_corres[i,2]]])
# for(i in 1:nrow(A_corres))ISNULL[i]<-is.null(xml_list[[A_corres[i,1]]][[A_corres[i,2]]])
# for(i in 1:nrow(A_corres))LENGTH[i]<-length(xml_list[[A_corres[i,1]]][[A_corres[i,2]]])
# for(i in 1:nrow(A_corres))DEPTH[i]<-ldepth(xml_list[[A_corres[i,1]]][[A_corres[i,2]]])
# for(i in 1:nrow(A_corres))NAMES[[i]]<-names(xml_list[[A_corres[i,1]]][[A_corres[i,2]]])
# tapply(LENGTH,level1[A_corres[,3],"name"],table)
# table(unlist(NAMES[A_corres$level1_match==1]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==2]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==3]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==4]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==5]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==6]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==7]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==8]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==9]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==10]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==11]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==12]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==13]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==14]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==15]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==16]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==17]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==18]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==19]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==20]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==21]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==22]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==23]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==24]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==25]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==26]),useNA = "ifany")
# table(unlist(NAMES[A_corres$level1_match==27]),useNA = "ifany")
```


Algoritmo que permite navegar en toda la estructura de los xml.
Basado en 2 tablas:

1. tabla que describe la jerarquía de los campos potenciales
1. tabla que describe la presencia de los campos para los registros

Note: the following function get the elements from a recursive path

```{r}
recPathList<-function(listNavig,path)
{
  x=listNavig
  for(i in path)
    x <- x[[i]]
  return(x)
}
# example
```

Lo que hacemos primero es crear una matriz que contiene todo los paths, nivel por nivel que existen en la lista representando el XML.
Anotar: cuando el nivel siguiente no es una lista, no fila está añadida.

```{r}
require(collapse)
listStruct<-matrix(data=c(1:length(xml_list),rep(NA,length(xml_list)*(ldepth(xml_list)-1))),nrow=length(xml_list),ncol=ldepth(xml_list))
findNextLevelPaths<-function(li,pathParent,maxDepth)
{
  if(!is.list(recPathList(li,pathParent))){return(NULL)}
  LN<-length(recPathList(li,pathParent))
  return(cbind(
    matrix(data=pathParent,nrow=LN,byrow=T,ncol=length(pathParent)),
    1:LN,
    matrix(NA,nrow=LN,ncol=maxDepth-(length(pathParent)+1))
  ))
}
for(i in 2:ncol(listStruct))
{
  cat("number of parents",sum(apply(listStruct,1,function(x)length(na.omit(x)))==(i-1)),"\n")
listStruct<-rbind(listStruct,
                  Reduce(rbind,apply(listStruct[apply(listStruct,1,function(x)length(na.omit(x)))==(i-1),],1,function(p,l,ml)
  {
  p=p[!is.na(p)]
  findNextLevelPaths(l,p,ml)
  },l=xml_list,ml=ncol(listStruct),simplify = F))
)
}
```


Now let's apply a function to transform this matrix in a name matrix.

```{r}
#nameCurrentLevel<-apply(listStruct[apply(listStruct,1,function(x)length(na.omit(x)))>1,],1,function(x,li)
nameCurrentLevel<-apply(listStruct,1,function(x,li)
{
  A<-na.omit(x)
  last<-A[length(A)]
  path<-A[-length(A)]
  names(recPathList(li,path))[last]
},li=xml_list)
nameCurrentLevel[(length(nameCurrentLevel)-50):length(nameCurrentLevel)]

allNames<-matrix(NA,nrow=nrow(listStruct),ncol=ncol(listStruct)-1)
for(i in 1:nrow(listStruct))
{
  if(i%%50000==0)cat(i,"/",nrow(listStruct),"\n")
  for(j in 2:max(2,length(na.omit(listStruct[i,]))))
  {
    
    path<-listStruct[i,1:(j-1)]
    last<-listStruct[i,j]
    allNames[i,j-1]<-names(recPathList(xml_list,path))[last]
  }
}
```

Desde el nivel 2 hasta maximo, determinamos cual es el parent:

```{r}
level<-apply(listStruct,1,function(x)length(na.omit(x)))
parent<-integer(nrow(listStruct))
for(i in 2:max(level))
{
  m<-match(apply(listStruct[level==i,],1,function(x){x[which.max(which(!is.na(x)))]<-NA;return(x)},simplify = F),split(listStruct[level==(i-1),],row(listStruct[level==(i-1),])))
  parent[level==i]<-which(level==(i-1))[m]
}
```




Cuales son los hijos directos?

```{r}
directChildren<-list()
for(i in 1:length(parent))
{
  directChildren[[i]]<-which(parent==i)
}
```


```{r}
allChildren<-vector(mode="list",length(directChildren))
for(i in 1:length(allChildren))
{
  newChildren<-children<-directChildren[[i]]
  while(length(newChildren)>0)
  {
    newChildren<-unlist(directChildren[newChildren])
    children<-c(children,newChildren)
  }
  allChildren[[i]]<-children
}
```

## Repetitions

From the children list, we may see what are the repetitions.

`directChildren` takes all nivels in the `listStruct` object which describes all the hierarchical levels in the xml. For each of these levels (each row of `listStruct`), it gives the children. It results in a list which contains all rows of `listStruct`, without duplication:


```{r}
length(directChildren)
any(duplicated(unlist(directChildren)))
```

Hence, we can use this simple list to see whether there are repetitions there of the names, which are in nameCurrentLevel

```{r}
nameChildren<-lapply(directChildren,function(x,n){n[x]},n=nameCurrentLevel)
dupliNameChildren<-lapply(nameChildren,duplicated)
anyDupliNameChildren<-sapply(dupliNameChildren,any)
```

Using mapply (to apply a function to corresponding elements of various list), we may use, in the cases where there are various children with the same names:

```{r}
# La función numRep da el indice de repetición en un
# NOTE: not sure how it would react to NA
numRep<-function(x)
{
  x<-factor(x)
  un<-levels(x)
  m<-match(x,un)
  t<-table(x)
  res<-integer(length(x))
  res[order(m)]<-unlist(lapply(t,function(x)1:x))
  return(res)
}
```


```{r}
repetitions<-Reduce(rbind,mapply(function(id_listStruct,name,dupl)
{
  nameUn<-unique(name[dupl])
  mnD<-match(name,nameUn)
  num<-numRep(name)
  return(
    data.frame(
    id=id_listStruct[!is.na(mnD)],
    name=name[!is.na(mnD)],
    numRep=num[!is.na(mnD)]
  )
  )
}
  ,id_listStruct=directChildren[anyDupliNameChildren],name=nameChildren[anyDupliNameChildren],dupl=dupliNameChildren[anyDupliNameChildren],SIMPLIFY = F))
```


Now we will create a matrix with the same row as listStruct, the number of column corresponding to the number of variables which are potentially repeated in their parent:
for each level from listStruct, it gives us 

```{r}
repAllNames<-allNames[repetitions$id,]
unRep_allNames<-unique(repAllNames)
gps<-match(split(allNames,row(allNames)),split(unRep_allNames,row(unRep_allNames)))
listStructRep<-matrix(NA,nrow(listStruct),max(gps,na.rm=T))
for(i in 1:max(gps,na.rm=T))
{
  potential_rep<-which(gps==i)
  num_rep<-numRep(parent[potential_rep])# five the index of repetitions when it has the same parent
  allChildrenRep<-allChildren[potential_rep]
  listStructRep[potential_rep,i]<-num_rep
  listStructRep[unlist(allChildrenRep),i]<-rep(num_rep,sapply(allChildrenRep,length))
}
lev_rep<-tapply(level,gps,unique)# note it is the real level, not -1
gpInGp<-data.frame(gp=NULL,inGp=NULL)
for(i in 1:max(gps,na.rm=T))
{
  lowerLevels<-lev_rep<lev_rep[i]
  if(any(lowerLevels))
  {
    curLevNotNa <- listStructRep[!is.na(listStructRep[,i]),lowerLevels]
    lowerLevApply<-apply(curLevNotNa,2,function(x)any(!is.na(x)))
    if(any(lowerLevApply)){
      inGp<-which(lowerLevels)[which(lowerLevApply)]
      inGp<-inGp[length(inGp)]
      gpInGp<-rbind(gpInGp,data.frame(gp=i,inGp=inGp))
    }
  }
}
```



Now we will create a matrix of the same dimension as listStruct, with values 0 for the levels which exist, NA when the level does not exist and instead of 0, the number of the repetition when it does apply
```r
listStructRep<-matrix(0L,nrow(listStruct),ncol(listStruct))
listStructRep[is.na(listStruct)]<-NA
for(i in 1:nrow(repetitions))
{
  matrixAdd<-cbind(row=c(repetitions$id[i],allChildren[[repetitions$id[i]]]),
                   col=level[repetitions$id[i]])
  listStructRep[matrixAdd]<-repetitions$numRep[i]
}
```


## Extracting final variables (leaves of the xml tree)
Cuales son los path que contienen una lista
```{r}
contList<-apply(listStruct,1,function(x,li)
{path=na.omit(x);return(is.list(recPathList(li,path)))},li=xml_list)
```

Cuales son los casos que no contienen listas, pero son nulos:

```{r}
contNull<-apply(listStruct,1,function(x,li)
{path=na.omit(x);return(is.null(recPathList(li,path)))},li=xml_list)
noListButNull<-!contList&contNull
sum(!contList)
sum(noListButNull)
sum(!contList&!contNull)
```

```{r}
# which of listStruct is a non-null, non-list value
leaves<-which(!contList&!contNull)
# table of unique variable names
un_leaves<-unique(allNames[leaves,])
# correspondence between non-null, non-list values and unique variable names
m<-match(split(allNames[leaves,],row(allNames[leaves,])),split(un_leaves,row(un_leaves)))
# Correspondence between listStruct and unique variable names
corres_leaves<-integer(nrow(listStruct))
corres_leaves[leaves]<-m
```


Para cada variable (hoja), necesitamos saber:

* cuantas veces aparece?
* En cuantos registros aparece?
* En que grupo (repeticiones) está?
* cual es el minimo/maximo de la longitud del vector de valores?
* ejemplos de valores
* Que es la secuencia de nombre de campos xml?

```{r}
# Cuantas veces aparece?
nbOccurrences<-table(corres_leaves[corres_leaves!=0])
# En cuantos registros
nbReg<-tapply(listStruct[,1],corres_leaves,function(x)length(unique(x)))[-1]
# En cual gp

inRep<-inGp<-tapply(apply(listStructRep[leaves,],1,function(x){
  w<-which(!is.na(x))
  if(length(w)){return(max(w))}
  return(0)
}),corres_leaves[leaves],unique)
# Longitud de valores
rangeLN<-by(listStruct[corres_leaves!=0,],corres_leaves[corres_leaves!=0],FUN=function(tab,ls_xml)
  {
    ls_byVar<-apply(tab,1,FUN=function(x,l_x)recPathList(ls_xml,na.omit(x)),l_x=ls_xml,simplify=F)
    return(range(sapply(ls_byVar,length)))
  },ls_xml=xml_list)
len_min<-sapply(rangeLN,min)
len_max<-sapply(rangeLN,max)

subNames<-by(listStruct[corres_leaves!=0,],corres_leaves[corres_leaves!=0],FUN=function(tab,ls_xml)
  {
    subN<-unique(unlist(lapply(apply(tab,1,FUN=function(x,l_x)recPathList(ls_xml,na.omit(x)),l_x=ls_xml,simplify = F),names)))
    return(paste(subN,sep="|",collapse="|"))
  },ls_xml=xml_list)

examples<-as.list(by(listStruct,corres_leaves,FUN=function(tab,ls_xml)
  {
    ls_byVar<-apply(tab,1,FUN=function(x,l_x)recPathList(ls_xml,na.omit(x)),l_x=ls_xml)
  },ls_xml=xml_list)[-1])
NAMES<-apply(un_leaves,1,function(x)paste(na.omit(x),collapse="_"))
isAttr<-grepl("\\.attr",NAMES)
```


Now we export a csv file to be able to analyse and name the variables:
```{r}
un_leaves<-data.frame(id=1:nrow(un_leaves),
                      un_leaves,
                      inRep,
                      isAttr,
                      nbOccurrences,
                      nbReg,
                      len_min,
                      len_max,
                      subNames
                      )

write.csv(un_leaves,file="../../../data_metadatos_catalogos/ceiba_un_leaves.csv")
```


## Managing names without repetitions in gp

Tenemos que dar nombres a los grupos, a las variables, que no se repiten en los grupos.

```{r}
nameGp <- apply(unRep_allNames,1,function(x){A<-na.omit(x);A[length(A)]})
gp_info<-data.frame(
                        refUn=1:nrow(unRep_allNames),
                        name=nameGp,
                        varPath=apply(unRep_allNames,1,function(x)paste(na.omit(x),collapse="|")),
                        inGp=0
                        )
gp_info[match(gpInGp$gp,gp_info$refUn),"inGp"]<-gpInGp$inGp
```



```{r}
namesVar<-apply(un_leaves[grep("^X",colnames(un_leaves))],1,function(x)
  {A<-na.omit(x)
  A[length(A)]
  })
var_info<-data.frame(
  refUn=un_leaves$id,
  name=namesVar,
  varPath=apply(un_leaves[grep("^X",colnames(un_leaves))],1,function(x)paste(na.omit(x),collapse="|")),
  inGp=inGp,
  subNames=un_leaves$subNames
                   )
```

```{r}
repeatedNames_var<-by(var_info,var_info$inGp,function(x)
{
  dupliNames<-x$name[duplicated(x$name)]
  res<-x[x$name%in%dupliNames,c("refUn","name","varPath")]
})
repeatedNames_var<-repeatedNames_var[sapply(repeatedNames_var,nrow)>0]
nbNamesToTake<-1
while((length(repeatedNames_var)>0 & nbNamesToTake < ldepth(xml_list)) && (sum(sapply(repeatedNames_var,length))>0 ))
{
nbNamesToTake<-nbNamesToTake + 1
toModif<-Reduce(rbind,lapply(repeatedNames_var,function(x,n){
  replacement<-lapply(strsplit(x$varPath,"\\|"),function(x,n)
    paste(x[max(length(x)-(n-1),1):length(x)],collapse="_")
  ,n=n)
  x$name<-unlist(replacement)
  return(x)
}
,n=nbNamesToTake))
for(i in 1:nrow(toModif))
{
  var_info$name[var_info$refUn==toModif$refUn[i]]<-toModif$name[i]
}
repeatedNames_var<-by(var_info,var_info$inGp,function(x)
{
  dupliNames<-x$name[duplicated(x$name)]
  res<-x[x$name%in%dupliNames,c("refUn","name","varPath")]
  return(res)
})
repeatedNames_var<-repeatedNames_var[sapply(repeatedNames_var,nrow)>0]
}
```

```{r}
repeatedNames_gp<-by(gp_info,gp_info$inGp,function(x)
{
  dupliNames<-x$name[duplicated(x$name)]
  res<-x[x$name%in%dupliNames,c("refUn","name","varPath")]
})
repeatedNames_gp<-repeatedNames_gp[sapply(repeatedNames_gp,nrow)>0]
nbNamesToTake<-1
while((length(repeatedNames_gp)>0 & nbNamesToTake < ldepth(xml_list)) && (sum(sapply(repeatedNames_gp,length))>0 ))
{
nbNamesToTake<-nbNamesToTake + 1
toModif<-Reduce(rbind,lapply(repeatedNames_gp,function(x,n){
  replacement<-lapply(strsplit(x$varPath,"\\|"),function(x,n)
    paste(x[max(length(x)-(n-1),1):length(x)],collapse="_")
  ,n=n)
  x$name<-unlist(replacement)
  return(x)
}
,n=nbNamesToTake))
for(i in 1:nrow(toModif))
{
  gp_info$name[gp_info$refUn==toModif$refUn[i]]<-toModif$name[i]
}
repeatedNames_gp<-by(gp_info,gp_info$inGp,function(x)
{
  dupliNames<-x$name[duplicated(x$name)]
  res<-x[x$name%in%dupliNames,c("refUn","name","varPath")]
  return(res)
})
repeatedNames_gp<-repeatedNames_gp[sapply(repeatedNames_gp,nrow)>0]
}
```

# Representation of the variable structure

```{r}
# We changed gp_var_info for gp_info and var_info
# What we should do now is:
# 1. manage the gp_path variable in the gp_info table
# 2. add the gp_path variable in the var_info table from the gp_info gp_path and ingp variable
# 3. feed the gp_path variable from the var_info table to the data.tree structure (Node)
# 4. manage the labels in the data.tree (Node) structure from the table gp_info and var_info


require(data.tree)

gp_info$gp_path<-NA
gp_info$gp_path[gp_info$inGp==0]<-paste0("gp_0/gp_",gp_info$refUn[gp_info$inGp==0])
while(any(is.na(gp_info$gp_path))){
  ref<-which(is.na(gp_info$gp_path))
  ref<-ref[!is.na(gp_info$gp_path[gp_info$inGp[ref]])]
  gp_info$gp_path[ref]<-paste0(gp_info$gp_path[gp_info$inGp[ref]],"/gp_",gp_info$refUn[ref])
}

var_info$gp_path<-NA
var_info$gp_path[var_info$inGp==0]<-paste0("gp_0/var_",var_info$refUn[var_info$inGp==0])
var_info$gp_path[var_info$inGp!=0]<-paste0(gp_info$gp_path[var_info$inGp[var_info$inGp!=0]],"/var_",var_info$refUn[var_info$inGp!=0])
  
dataTreeGpVar<-rbind(
  data.frame(gp_info[c("refUn","gp_path")],name=paste0("gp_",gp_info$refUn),label=gp_info$name,gp_var="gp",gp_col=gp_info$refUn),
  data.frame(var_info[c("refUn","gp_path")],name=paste0("var_",var_info$refUn),label=var_info$name,gp_var="var",gp_col=var_info$inGp)
)
nodeGpVar<-FromDataFrameTable(dataTreeGpVar,"gp_path")
print(nodeGpVar,"label",pruneMethod = NULL)
```

```r fig.height=10,fig.width=2
SetGraphStyle(nodeGpVar,rankdir="LR")
SetNodeStyle(nodeGpVar,label=function(node)node$label)
plot(nodeGpVar)
```

```{r fig.height=15,fig.width=15}
library(igraph)
#png("testReprNetwork.pdf",1500,1500)
ig_gpVar<-as.igraph(nodeGpVar, directed = TRUE, direction = "climb")
str(ig_gpVar)
V(ig_gpVar)$gp_col<-dataTreeGpVar$gp_col[match(names(V(ig_gpVar)),dataTreeGpVar$name)]
V(ig_gpVar)["gp_0"]$gp_col<-0
V(ig_gpVar)$gp_var<-dataTreeGpVar$gp_var[match(names(V(ig_gpVar)),dataTreeGpVar$name)]
V(ig_gpVar)["gp_0"]$gp_var<-"var"
V(ig_gpVar)$label<-dataTreeGpVar$label[match(names(V(ig_gpVar)),dataTreeGpVar$name)]
V(ig_gpVar)["gp_0"]$label<-"dataset"

COL<-rainbow(max(V(ig_gpVar)$gp_col+1,na.rm = T))[V(ig_gpVar)$gp_col+1]

#gp_var_info[c("gp_var_name","name")][match(names(V(ig_gpVar)),gp_var_info$gp_var_name),]
plot(ig_gpVar,vertex.label=V(ig_gpVar)$label,vertex.size=5,vertex.shape=c(var="circle",gp="square")[V(ig_gpVar)$gp_var], vertex.color=COL)
```



# Exportation of a table with values and references (dataset and variables)

What we have got is:

* the table `un_leaves` which contains many characteristics of the different variables
* `listStruct` which contains all the paths in rows
* `corres_leaves`, which corresponds one on one to listStruct and which gives 0 when the path does not go to a "leaf" and gives the id of the table `un_leaves` when it is a leaf
* `xml_list` which contains all the info from the xml files, and might be accessed through the function `recPathList` with the path from `listStruct`
* `parent` which gives, for each of the line of `listStruct` the parent line, in `listStruct` as well 
* `addresses_xml` which contains, in the first column, the system path of the files xml, on the same order as the column 1 from `listStruct`: we can extract the name of the folder from there...
* `listStructRep` corresponde exactamente a `listStructRep` en terminos de row y columns, vale NA en los levels que no conciernen la fila, 0 cuando no hay repetición (incluso cuando puede haber repetición para la variable), y el numero de repetición dentro de un parent cuando aplique
* `gp_var_info` contiene toda la información sobre la estructura de tablas y de relaciones entre tablas


One of the difficulties we could have to extract the table of values is that some leaves (some of the .attr ones only) have more than one value on the leaves


Here is an attempt to extract all leaves in a simple table, in a "dataset->var->value" schema which do not account for the repeated variables and their groups.
```{r}
recalculate<-F
folder <- gsub("^.*/","",dirname(addresses_xml$file))
if(recalculate){
res<-Reduce(rbind,lapply(leaves,function(x,f,lS,cl,xl,p,ul)
  {
  val <- recPathList(xl,na.omit(lS[x,]))
  nameVal <- names(val)
  if(is.null(nameVal)){nameVal<-NA}
  return(data.frame(
    ref_struct=x,
    parent=p[x],
    folder=f[lS[x,1]],
    id_var=cl[x],
    subname=nameVal,
    value=as.character(val)
  ))},
  f=folder,
  lS=listStruct,
  cl=corres_leaves,
  xl=xml_list,
  p=parent,
  ul=un_leaves
  ))
save(res,file="../../../data_metadatos_catalogos/tab_variable.RData")
}else{(load(file="../../../data_metadatos_catalogos/tab_variable.RData"))}
```

Now if we want to account for the repeated variables and their groups, we need to:

1. for each leaf give it its `gp` (table) and reference `inGp` in terms of ids
1. create the table as matrix of character
1. go through the leaf table and put the values in the corresponding table
1. determine the type of the variables and transform the matrix into data.frame that may be exported in a database


```{r}
#Step 1:for each leaf give it its `gp` (table) and reference `inGp` in terms of ids
matGp <- cbind(listStruct[leaves,1],listStructRep[leaves,])
colnames(matGp)<-c(0,1:ncol(listStructRep))
gpLeaves <- var_info$inGp[corres_leaves[leaves]]
varLeaves <- corres_leaves[leaves]
```


```{r}
#Step 2: prep the matrix
# Extract colnames for every table
varGp<-tapply(apply(var_info[c("name","subNames")],1,function(x)
{
  if(x[2]==""){return(x[1])}
  return(paste(x[1],unlist(strsplit(x[2],"\\|")),sep="_"))
}),var_info$inGp,unlist)
# get info to preparing the tables
prepTables<-list()
for(i in colnames(matGp)){
  gp<-as.integer(i)
  un_gp<-unique(matGp[gpLeaves==gp,])
  prepTables[[as.name(i)]]<-list(
    gp=gp,
    nameTable=gp_info$name[gp_info$refUn==gp],
    un_gp=un_gp,
    fields=varGp[[i]]
  )
}
#There is no tableName for the gp0
prepTables[["0"]]$nameTable<-"dataset"

#Step3 create the matrices and fill their contents
matData<-list()
for(i in 1:length(prepTables))
{
  gp<-prepTables[[i]]$gp
  #Create empty matrix
  matData[[i]]<-matrix(NA,nrow(prepTables[[i]]$un_gp),length(prepTables[[i]]$fields),dimnames=list(NULL,prepTables[[i]]$fields))
  #extract content of each corresponding leaf for the group
  content<-apply(listStruct[leaves,][gpLeaves==prepTables[[i]]$gp,],1,function(x)recPathList(xml_list,na.omit(x)),simplify = F)
  #for each content extraction which row of the matrix corresponds 
  rowM<-match(split(matGp[gpLeaves==prepTables[[i]]$gp,],row(matGp[gpLeaves==prepTables[[i]]$gp,])),split(prepTables[[i]]$un_gp,row(prepTables[[i]]$un_gp)))
  # which var correspond (var number)
  varM<-varLeaves[gpLeaves==gp]
  # get the name from the var number
  field_complete<-vector(mode = "list",length=length(varM))
  hasSubnames<-var_info[varM,]$subNames!=""
  field_complete[!hasSubnames]<-as.list(var_info[varM,"name"][!hasSubnames])
  field_complete[hasSubnames]<-mapply(function(x,y){paste(x,names(y),sep="_")},
                                      x=var_info[varM,"name"][hasSubnames],
                                      y=content[hasSubnames],SIMPLIFY = F)
  # Step 4: filling the tables
  matData[[i]][
    cbind(row=rep(rowM,sapply(content,length)),
          col=match(unlist(field_complete),colnames(matData[[i]]))
          )
    ]<-unlist(content)
}
```


Creating id for each table and hierarchical level:


```{r}
# What id (primary and foreign key) do need each table
primaryKey <- sapply(prepTables,function(x)paste0("cd_",x$nameTable))
m<-match(names(prepTables), as.character(gp_info$refUn))
foreignKey<-primaryKey[as.character(gp_info$inGp[m])]
names(foreignKey) <- names(prepTables)
foreignTables<-sapply(prepTables[as.character(gp_info$inGp[m])],function(x){
  if(is.null(x)){return(NA)}
  return(x$nameTable)
})
parentGp<-as.character(gp_info$inGp[m])
foreignKeyMatch<-list()
for(i in 1:length(prepTables))
{
  if(is.na(parentGp[i]))
  {
    foreignKeyMatch[[i]]<-NA
    next
  }
  gpC<-names(prepTables)[i]
  mat1 <- prepTables[[i]]$un_gp[,-i]
  mat2 <- prepTables[[as.character(parentGp[i])]]$un_gp[,-i]
  foreignKeyMatch[[i]]<-match(split(mat1,row(mat1)),split(mat2,row(mat2)))
}
```

```{r}
finalTables<-vector(mode="list",length(matData))
for(i in 1:length(finalTables))
{
  if(is.na(foreignKey[i]))
  {
    preamble<-data.frame(primaryKey=1:nrow(matData[[i]]))
    names(preamble)<-primaryKey[i]
  }else{
    preamble<-data.frame(primaryKey=1:nrow(matData[[i]]),
                         foreignKey=foreignKeyMatch[[i]])
    names(preamble)<-c(primaryKey[i],foreignKey[i])
  }
  finalTables[[i]]<-cbind(preamble,lapply(as.data.frame(matData[[i]]),type.convert,as.is=T))
}
names(finalTables)<-sapply(prepTables,function(x)x$nameTable)
```

## Crear la base de datos

```{r}
require(RSQLite)
dbFile<-"../../../data_metadatos_catalogos/metadata_ceiba.sqlite"
if(file.exists(dbFile)){file.remove(dbFile)}
metaCeiba<-dbConnect(SQLite(),dbFile)
```

## Crear las primeras tablas

### Información de grupos de variables

For now we will only create the tables gp_info, var_info and sub_var_info, to describe the way final tables and var were managed in the xml files:

```{r}
statement<-
"CREATE TABLE gp_info(
  cd_gp int PRIMARY KEY,
  name text,
  xml_path text,
  in_gp int REFERENCES gp_info(cd_gp),
  gp_path text,
  UNIQUE(name,in_gp));
"
dbExecute(metaCeiba,statement)
statement<-
"CREATE TABLE var_info(
  cd_var int PRIMARY KEY,
  name text,
  xml_path text,
  in_gp int REFERENCES gp_info(cd_gp),
  gp_path text,
  UNIQUE (name,in_gp)
);"
dbExecute(metaCeiba,statement)
statement<-
"CREATE TABLE subvar_info
(
  cd_subvar int PRIMARY KEY,
  cd_var int REFERENCES var_info(cd_var),
  subname text,
  unique(cd_var,subname)
);
"
dbExecute(metaCeiba,statement)
dbExecute(metaCeiba,"CREATE INDEX fk_gp_info_in_gp_idx ON gp_info(in_gp);")
dbExecute(metaCeiba,"CREATE INDEX fk_var_info_in_gp_gp_info_idx ON var_info(in_gp);")
dbExecute(metaCeiba,"CREATE INDEX fk_subvar_info_cd_var_var_info_idx ON subvar_info(cd_var);")
```

**Inserting the data:**

We start by inserting the 0 level, which is not in the R objects
```{r}
tab0<-data.frame(
  refUn=0,
  name="dataset",
  varPath="",
  inGp=NA,
  gp_path="gp_0"
  )
colnames(tab0)<-dbListFields(metaCeiba,Id(table="gp_info"))
dbAppendTable(metaCeiba,Id(table="gp_info"),value=tab0)
```

Then we insert other information about the groups from the R object:

```{r}
tab1<-gp_info
colnames(tab1)<-dbListFields(metaCeiba,Id(table="gp_info"))
dbAppendTable(metaCeiba,Id(table="gp_info"),value=tab1)
```

Now we insert information about the variables:

```{r}
tab1<-var_info[c("refUn","name","varPath","inGp","gp_path")]
colnames(tab1)<-dbListFields(metaCeiba,"var_info")
dbAppendTable(metaCeiba,Id(table="var_info"),value=tab1)
```

And the subVar table:

```{r}
sp<-strsplit(var_info$subNames,"\\|")
dbAppendTable(metaCeiba,Id(table="subvar_info"),
data.frame(cd_subvar=1:length(unlist(sp)),
           cd_var=rep(var_info$refUn,sapply(sp,length)),
           subname=unlist(sp)
           )
)
```


## Crear the metadata tables

```{r}
for(i in 1:length(finalTables))
{
  gp<-names(prepTables)[i]
  quotedCol<-dbQuoteIdentifier(metaCeiba,colnames(finalTables[[i]]))
  types<-dbDataType(metaCeiba,finalTables[[i]])
  pk<-ifelse(colnames(finalTables[[i]])==primaryKey[i]," PRIMARY KEY","")
  fk<-character(length(quotedCol))
  if(!is.na(foreignKey[i])){
    w<-which(colnames(finalTables[[i]])==foreignKey[i])
    fk[w]<-paste0(" REFERENCES ",dbQuoteIdentifier(metaCeiba,Id(table=foreignTables[i])),"(",dbQuoteIdentifier(metaCeiba,foreignKey[i]),")")
  }
  dbExecute(metaCeiba,paste0("CREATE TABLE ",dbQuoteIdentifier(metaCeiba,Id(prepTables[[i]]$nameTable)),"(",paste(quotedCol,types,pk,fk, collapse=","),")"))
  if(!is.na(foreignKey[i])){
    dbExecute(metaCeiba,paste0("CREATE INDEX fk_",prepTables[[i]]$nameTable,"_",foreignKey[i],"_",foreignTables[i],"_idx ON ",dbQuoteIdentifier(metaCeiba,Id(table=prepTables[[i]]$nameTable))," (",dbQuoteIdentifier(metaCeiba,foreignKey[i]),");")) 
  }
  dbAppendTable(metaCeiba,dbQuoteIdentifier(metaCeiba,Id(prepTables[[i]]$nameTable)),finalTables[[i]])
}
```


## Particularidad del IPT: registro de archivos

```{r}
folderBase<-"/home/pem/datadir/resources/"
baseLength<-length(strsplit(folderBase,"/")[[1]])
dbExecute(metaCeiba,"CREATE TABLE files(cd_file INT PRIMARY KEY,root_folder TEXT, file TEXT, complete_path TEXT);")
dbExecute(metaCeiba,"CREATE INDEX files_root_folder_idx ON files(root_folder);")
dataFiles<-data.frame(
  cd_file=1:length(result_find),
  root_folder=sapply(strsplit(result_find,"/"),function(x)x[baseLength+1]),
  file=basename(result_find),
  complete_path=result_find
)
dbAppendTable(metaCeiba,Id(table="files"),dataFiles)
```

Reference in the dataset table:

```{r}
if(!"cd_file" %in% dbListFields(metaCeiba,"dataset")){
dbExecute(metaCeiba,"ALTER TABLE dataset ADD COLUMN cd_file INT REFERENCES files(cd_file);")

dbWriteTable(metaCeiba,"tmp_corres_dataset_file",
             data.frame(
               cd_dataset=1:nrow(addresses_xml),
               cd_file=match(addresses_xml$file,dataFiles$complete_path)
             ))
dbExecute(metaCeiba,"UPDATE dataset AS d
          SET cd_file=tcdf.cd_file
          FROM tmp_corres_dataset_file tcdf
          WHERE tcdf.cd_dataset=d.cd_dataset;")
dbRemoveTable(metaCeiba,"tmp_corres_dataset_file")
}
```




# Export finalTables Excel
```{r}
require(openxlsx)
write.xlsx(finalTables,file="../../../data_metadatos_catalogos/meta_ceiba.xlsx")
```


# Apagar la luz y salir

```{r}
dbDisconnect(metaCeiba)
```

